import pandas as pd
import plotly.express as px

from linearmodels.panel import PanelOLS
from sklearn.cluster import KMeans
from sklearn.cross_decomposition import PLSRegression
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
from sklearn.metrics import silhouette_score, silhouette_samples

from ui.chart_board import display_goodprice_map, plot_grouped_bar, plot_grouped_bar_ratio, save_all_clusters_goodprice_map
from util.common_util import apply_log_transform, check_outliers_std, check_variable_skewness, compute_rmsle_from_result, drop_outlier_rows_std, load_clustered_geodataframe, save_full_model_output
from util.common_util import apply_zscore_scaling

from scipy.cluster.hierarchy import linkage, fcluster
from scipy.stats import chi2_contingency
from statsmodels.stats.proportion import proportions_ztest


# ===============================================================================
#  1. íšŒê·€_ë¶„ì„
#  [Model1]
#   H1. ì§€ì—­ ë‚´ ì™¸ì‹ì§€ì¶œë¹„ê°€ ë†’ì€ì§€ì—­ì¼ìˆ˜ë¡ ì°©í•œê°€ê²©ì—…ì†Œ ìˆ˜ ë¹„ì¤‘ì´ ê°ì†Œí•œë‹¤. - ê²€ì¦ 
#   H2. ì§€ì—­ ë‚´ íì—…ë¥ ì´ ë†’ì€ì§€ì—­ì¼ìˆ˜ë¡ ì°©í•œê°€ê²©ì—…ì†Œ ìˆ˜ ë¹„ì¤‘ì´ ì¦ê°€í•œë‹¤ - ê²€ì¦ 
#   H3. ì§€ì—­ ë‚´ ìƒê¶Œì¶•ì†Œ ì§€ì—­ì¼ìˆ˜ë¡ ì°©í•œê°€ê²©ì—…ì†Œ ìˆ˜ ë¹„ì¤‘ì´ ì¦ê°€í•œë‹¤. - ê²€ì¦
#   H4. ì§€ì—­ ë‚´ 20_30ëŒ€ ì¸êµ¬ë¹„ê°€ ë†’ì€ì§€ì—­ì¼ìˆ˜ë¡ ì°©í•œê°€ê²©ì—…ì†Œ ìˆ˜ ë¹„ì¤‘ì´ ê°ì†Œí•œë‹¤. - ê¸°ê° 
#   [Model2]
#   H6. ì§€ì—­ ë‚´ ìƒê¶Œì¶•ì†Œ ì§€ì—­ì— ë”°ë¼ 20_30ëŒ€ ì¸êµ¬ë¹„ê°€ ì°©í•œê°€ê²©ì—…ì†Œ ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ë‹¤ë¥¼ ê²ƒì´ë‹¤.
#   [Model3]
#   ì¶”ê°€. H2,H3,H4 ì˜ lag_1 ë…ë¦½ ì‹œì°¨ë³€ìˆ˜ë¥¼ í†µí•´ ì—­ì¸ê³¼ì„±ì— ëŒ€í•œ ê°•ê±´ì„± ê²€ì¦ 
# ===============================================================================
df_GoodPrice = pd.read_csv('./model/ìƒê¶Œ_ì°©í•œê°€ê²©ì—…ì†Œ_ë³‘í•©.csv', encoding='utf-8')

# ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡ íŒŒìƒë³€ìˆ˜ ìƒì„±
df_GoodPrice['ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡'] = df_GoodPrice.apply(
    lambda row: 0 if row['ì í¬_ìˆ˜'] == 0 or pd.isna(row['ì í¬_ìˆ˜'])
    else int(np.floor(row['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'] / row['ì í¬_ìˆ˜'])),
    axis=1
)

# íƒ€ì…ë³€í™˜ 
df_GoodPrice['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'] = df_GoodPrice['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].astype(int)
# ì´_ìœ ë™ì¸êµ¬ 
df_GoodPrice['ì´_ìœ ë™ì¸êµ¬_ìˆ˜'] = df_GoodPrice['ë‚¨ì„±_ìœ ë™ì¸êµ¬_ìˆ˜'] + df_GoodPrice['ì—¬ì„±_ìœ ë™ì¸êµ¬_ìˆ˜'] 

# 10~30ëŒ€ ìœ ë™ì¸êµ¬ í•©ê³„ 
df_GoodPrice['ìœ ë™ì¸êµ¬_10_30ëŒ€'] = (
    df_GoodPrice['ì—°ë ¹ëŒ€_10_ìœ ë™ì¸êµ¬_ìˆ˜'] +
    df_GoodPrice['ì—°ë ¹ëŒ€_20_ìœ ë™ì¸êµ¬_ìˆ˜'] +
    df_GoodPrice['ì—°ë ¹ëŒ€_30_ìœ ë™ì¸êµ¬_ìˆ˜']
)

# 40~60ëŒ€ ì´ìƒ ìœ ë™ì¸êµ¬ìˆ˜ í•©ê³„
df_GoodPrice['ìœ ë™ì¸êµ¬_40_ì´ìƒ'] = (
    df_GoodPrice['ì—°ë ¹ëŒ€_40_ìœ ë™ì¸êµ¬_ìˆ˜'] +
    df_GoodPrice['ì—°ë ¹ëŒ€_50_ìœ ë™ì¸êµ¬_ìˆ˜'] +
    df_GoodPrice['ì—°ë ¹ëŒ€_60_ì´ìƒ_ìœ ë™ì¸êµ¬_ìˆ˜']
)

# ì´_ì§ì¥ì¸êµ¬
df_GoodPrice['ì´_ì§ì¥ì¸êµ¬_ìˆ˜'] = df_GoodPrice['ë‚¨ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜'] + df_GoodPrice['ì—¬ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜'] 
# ì§€ì—­ë³„ ì í¬ìˆ˜ ëŒ€ë¹„ ì—…ì†Œìˆ˜ 
df_GoodPrice['ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘'] = (
    df_GoodPrice['ì—…ì†Œìˆ˜'] / df_GoodPrice['ì í¬_ìˆ˜']
).round(3)

# ì„ì‹œì½”ë“œ(20234~20244 ë¶„ê¸° í•œì •)
df_GoodPrice = df_GoodPrice[df_GoodPrice['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].isin([20233, 20241, 20242, 20243, 20244])]

# / ëŒ€ì²´ - íšŒê·€ë¶„ì„ì—ì„œ ì¸ì‹ì˜¤ë¥˜  
# df_GoodPrice['ìƒê¶Œëª…']= df_GoodPrice['ìƒê¶Œëª…'].str.replace('/', '', regex=False)

# 1. ë°ì´í„° ì¸ë±ìŠ¤ ì„¤ì •
df_panel = df_GoodPrice.set_index(['í–‰ì •ë™_ì½”ë“œ', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ']).sort_index()

# 2. ë”ë¯¸ ë³€ìˆ˜ ìƒì„±
time_dummies = pd.get_dummies(df_panel.reset_index()['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'], prefix='ë¶„ê¸°', drop_first=True)

# 3. ê¸°ì¡´ ë³€ìˆ˜ì™€ ë”ë¯¸ ë³‘í•©
df_model = pd.concat([
    df_panel.reset_index(drop=True),
    time_dummies
], axis=1)

# 4. ì¸ë±ìŠ¤ ì¬ì„¤ì •
df_model = df_model.set_index(df_panel.index).sort_index()

# 5. ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ ì›í•« ì¸ì½”ë”©
df_model = pd.get_dummies(df_model, columns=['ìƒê¶Œ_ë³€í™”_ì§€í‘œ'], drop_first=False)
df_model = df_model.drop(columns=['ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HH'])

# 6. ë‹¤ì¤‘ê³µì„ ì„± í™•ì¸ corr Matrix 
# ë‹¤ì¤‘ê³µì„ ì„± í™•ì¸ ëŒ€ìƒ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸
cols = ['ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡', 'ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡', 'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡','ì˜ë£Œë¹„_ì§€ì¶œ_ì´ê¸ˆì•¡','êµìœ¡_ì§€ì¶œ_ì´ê¸ˆì•¡',
        'ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜', 'ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜', 'ìœ ë™ì¸êµ¬_10_30ëŒ€', 'ìœ ë™ì¸êµ¬_40_ì´ìƒ', 'ì´_ì§ì¥ì¸êµ¬_ìˆ˜', 'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜','ì§‘ê°ì‹œì„¤_ìˆ˜','ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´','íì—…_ì˜ì—…_ê°œì›”_ì°¨ì´','ê°œì—…_ë¥ ','íì—…_ë¥ ',
        '1ì¸_ê°€êµ¬ë¹„','20_30_ì¸êµ¬ë¹„','31_50_ì¸êµ¬ë¹„','51_75_ì¸êµ¬ë¹„']

# corr_matrix
corr_matrix = df_model[cols].dropna().corr().round(2)

# íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
fig = px.imshow(
    corr_matrix,
    text_auto=True,
    color_continuous_scale='RdBu_r',
    aspect='auto',
    title='ğŸ“Š ë³€ìˆ˜ ê°„ ìƒê´€ê³„ìˆ˜ íˆíŠ¸ë§µ (Plotly)'
)

fig.update_layout(
    width=800,
    height=700,
    margin=dict(l=50, r=50, t=50, b=50),
    coloraxis_colorbar=dict(title="ìƒê´€ê³„ìˆ˜")
)

fig.show()

# 7. VIF í™•ì¸ 
vif_cols = ['ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡', 'ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€', 'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡','ì˜ë£Œë¹„_ì§€ì¶œ_ì´ê¸ˆì•¡','êµìœ¡_ì§€ì¶œ_ì´ê¸ˆì•¡',
            'ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜', 'ì´_ìœ ë™ì¸êµ¬_ìˆ˜','ìœ ë™ì¸êµ¬_10_30ëŒ€','ìœ ë™ì¸êµ¬_40_ì´ìƒ', 'ì´_ì§ì¥ì¸êµ¬_ìˆ˜', 'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜','ì§‘ê°ì‹œì„¤_ìˆ˜','ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´','íì—…_ì˜ì—…_ê°œì›”_ì°¨ì´','ê°œì—…_ë¥ ','íì—…_ë¥ ',
            '1ì¸_ê°€êµ¬ë¹„','20_30_ì¸êµ¬ë¹„','31_50_ì¸êµ¬ë¹„','51_75_ì¸êµ¬ë¹„']

X = add_constant(df_model[vif_cols].dropna())
bool_cols = X.select_dtypes(include=['bool']).columns
X[bool_cols] = X[bool_cols].astype(float)

# VIF ê³„ì‚°
vif_data = pd.DataFrame()
vif_data['ë³€ìˆ˜'] = X.columns
vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# corr í° ì›”_í‰ê· ì†Œë“, ì§‘ê°ì‹œì„¤_ìˆ˜, ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´ ì œê±°
print(vif_data)

# 8. ì™œë„ í™•ì¸ & ë¡œê·¸ë³€í™˜ 
skew_test_columns = [
    'ì—…ì†Œìˆ˜',
    'ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘',
    'ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡',
    'ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡',
    'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡',
    'ì˜ë£Œë¹„_ì§€ì¶œ_ì´ê¸ˆì•¡',
    'êµìœ¡_ì§€ì¶œ_ì´ê¸ˆì•¡',
    'ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜',
    'ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€',
    'ì´_ìœ ë™ì¸êµ¬_ìˆ˜',
    'ìœ ë™ì¸êµ¬_10_30ëŒ€',
    'ìœ ë™ì¸êµ¬_40_ì´ìƒ',
    'ì´_ì§ì¥ì¸êµ¬_ìˆ˜',
    'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜',
    'ì§‘ê°ì‹œì„¤_ìˆ˜',
    'ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´',
    'íì—…_ì˜ì—…_ê°œì›”_ì°¨ì´',
    'ê°œì—…_ë¥ ',
    'íì—…_ë¥ ',
    '1ì¸_ê°€êµ¬ë¹„',
    '20_30_ì¸êµ¬ë¹„',
    '31_50_ì¸êµ¬ë¹„',
    '51_75_ì¸êµ¬ë¹„'
]

check_variable_skewness(df_model[skew_test_columns])

skew_columns = skew_test_columns.copy()
skew_columns.remove('ì´_ìƒì£¼ì¸êµ¬_ìˆ˜')       # ìƒì£¼ì¸êµ¬ìˆ˜ ëŒ€ì¹­ 
skew_columns.remove('ê°œì—…_ë¥ ')            # ê°œì—…ìœ¨
skew_columns.remove('íì—…_ë¥ ')            # íì—…ìœ¨
skew_columns.remove('íì—…_ì˜ì—…_ê°œì›”_ì°¨ì´')
skew_columns.remove('ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´')

# ìµœì¢…í™•ì •ëœ ë³€ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¡œê·¸ë³€í™˜ 
df_model = apply_log_transform(df_model, skew_columns)

# 9. ë…ë¦½ë³€ìˆ˜ ìµœì¢…í™•ì • 
# - ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log, ì§‘ê°ì‹œì„¤ ìˆ˜, ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´ëŠ” ë‹¤ì¤‘ê³µì„ ì„±ì´ ë†’ì•„ ì œê±°
ind_columns = [
    'ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡_log',
    'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'ì˜ë£Œë¹„_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'êµìœ¡_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log',
    'ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜_log',
    'ìœ ë™ì¸êµ¬_10_30ëŒ€_log',
    'ìœ ë™ì¸êµ¬_40_ì´ìƒ_log',
    'ì´_ì§ì¥ì¸êµ¬_ìˆ˜_log',
    'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜',
    'ì§‘ê°ì‹œì„¤_ìˆ˜_log',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH',
    'ê°œì—…_ë¥ ',
    'íì—…_ë¥ ',
    '1ì¸_ê°€êµ¬ë¹„_log',
    '20_30_ì¸êµ¬ë¹„_log',
    '31_50_ì¸êµ¬ë¹„_log'
]
dep_columns= ['ì—…ì†Œìˆ˜_log','ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘','ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘_log']
dummy_columns= ['ë¶„ê¸°_20241','ë¶„ê¸°_20242','ë¶„ê¸°_20243','ë¶„ê¸°_20244']

# 10. ì´ìƒì¹˜ íŒŒì•… í›„ ì œê±° 
check_outliers_std(df_model[ind_columns],3.0)
df_model_drop_outlier = drop_outlier_rows_std(df_model, ind_columns)

scale_columns = ind_columns.copy()
scale_columns.remove('ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL')       
scale_columns.remove('ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL')            
scale_columns.remove('ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH')            

# 11. ë…ë¦½ë³€ìˆ˜ ë‹¨ìœ„ ìŠ¤ì¼€ì¼ë§
df_model_after_scaling = apply_zscore_scaling(df_model_drop_outlier,scale_columns)

selected_columns = ind_columns + dep_columns + dummy_columns
df_final = df_model_after_scaling[selected_columns].copy()
df_final.columns = df_final.columns.str.strip()

# -----------------------------------
# 12. Model1 íšŒê·€ì‹ êµ¬ì„± (ê°€ì„¤1,2,3,4)
# -----------------------------------
base_formula = 'ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘_log ~ 1 + ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡_log + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL + íì—…_ë¥  + ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡_log + ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log + ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜_log + ìœ ë™ì¸êµ¬_10_30ëŒ€_log + ìœ ë™ì¸êµ¬_40_ì´ìƒ_log + ì´_ì§ì¥ì¸êµ¬_ìˆ˜_log + ì§‘ê°ì‹œì„¤_ìˆ˜_log + ì´_ìƒì£¼ì¸êµ¬_ìˆ˜ + 20_30_ì¸êµ¬ë¹„_log + 31_50_ì¸êµ¬ë¹„_log'
dummy_formula = ' + '.join(time_dummies.columns.tolist())
full_formula = base_formula + ' + ' + dummy_formula

# PanelOLS ì í•©
model = PanelOLS.from_formula(full_formula, data=df_final)
result = model.fit()
print(result.summary)

# rmsle
rmsle = compute_rmsle_from_result(result, df_final)

# ëª¨ë¸1 ê²°ê³¼ ì €ì¥ 
save_full_model_output(result,rmsle,"./model/model1_results.csv")

# --------------------------------------------------------------------------
# 13. Model2 íšŒê·€ì‹ êµ¬ì„± (ê°€ì„¤6) - (ì¡°ì ˆë³€ìˆ˜ - ìƒí˜¸ì‘ìš© í•­) ì°©í•œê°€ê²©ì—…ì†Œìˆ˜ ë¹„ì¤‘ì˜ ì¶”ê°€ ì¦/ê° ê²€ì¦
# --------------------------------------------------------------------------
base_formula2 = 'ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘_log ~ 1 + ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡_log + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL + íì—…_ë¥  + ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡_log + ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log + ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜_log + ìœ ë™ì¸êµ¬_10_30ëŒ€_log + ìœ ë™ì¸êµ¬_40_ì´ìƒ_log + ì´_ì§ì¥ì¸êµ¬_ìˆ˜_log + ì§‘ê°ì‹œì„¤_ìˆ˜_log + ì´_ìƒì£¼ì¸êµ¬_ìˆ˜ + 20_30_ì¸êµ¬ë¹„_log + 31_50_ì¸êµ¬ë¹„_log + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL:20_30_ì¸êµ¬ë¹„_log + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH:20_30_ì¸êµ¬ë¹„_log + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL:20_30_ì¸êµ¬ë¹„_log '
dummy_formula2 = ' + '.join(time_dummies.columns.tolist())
full_formula2 = base_formula2 + ' + ' + dummy_formula2

# PanelOLS ì í•©
model2 = PanelOLS.from_formula(full_formula2, data=df_final)
result2 = model2.fit()
print(result2.summary)

# rmsle
rmsle2 = compute_rmsle_from_result(result2, df_final)

# ëª¨ë¸2 ê²°ê³¼ ì €ì¥ 
save_full_model_output(result2,rmsle2,"./model/model2_results.csv")

# -----------------------------
# 14. Model3 ì‹œì°¨ë³€ìˆ˜ ì¶”ê°€ í›„ ì¬ê²€ì¦ 
# -----------------------------
df_final = df_final.sort_values(by=['í–‰ì •ë™_ì½”ë“œ', 'ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'])

# ì‹œì°¨ ìƒì„± ëŒ€ìƒ ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸
lag_vars = [
    'íì—…_ë¥ ',
    'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL',
    '20_30_ì¸êµ¬ë¹„_log'
]

# ê° ë³€ìˆ˜ì— ëŒ€í•´ -1ë¶„ê¸° ì‹œì°¨ ìƒì„±
for var in lag_vars:
    df_final[f'{var}_lag1'] = df_final.groupby('í–‰ì •ë™_ì½”ë“œ')[var].shift(1)

# ì²« ë¶„ê¸° ì œê±°(lag1 ê°’ì´ null ì¸ ë¶„ê¸°)
first_quarter_idx = df_final.groupby('í–‰ì •ë™_ì½”ë“œ').head(1).index
df_lagged = df_final.drop(index=first_quarter_idx)

# íšŒê·€ì‹ êµ¬ì„± (ê°€ì„¤1, 2) - ì‹œì°¨ë³€ìˆ˜
lag_time_dummies = pd.get_dummies(df_lagged.reset_index()['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'], prefix='ë¶„ê¸°', drop_first=True)

base_formula3 = 'ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘_log ~ 1 + ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡_log + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL_lag1 + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH_lag1 + ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL_lag1 + íì—…_ë¥ _lag1 + ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡_log_lag1 + ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log + ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜_log + ìœ ë™ì¸êµ¬_10_30ëŒ€_log + ìœ ë™ì¸êµ¬_40_ì´ìƒ_log + ì´_ì§ì¥ì¸êµ¬_ìˆ˜_log + ì§‘ê°ì‹œì„¤_ìˆ˜_log + ì´_ìƒì£¼ì¸êµ¬_ìˆ˜ + 1ì¸_ê°€êµ¬ë¹„_log + 20_30_ì¸êµ¬ë¹„_log_lag1 + 31_50_ì¸êµ¬ë¹„_log'
dummy_formula3 = ' + '.join(lag_time_dummies.columns.tolist())
full_formula3 = base_formula3 + ' + ' + dummy_formula3

# PanelOLS ì í•©
model3 = PanelOLS.from_formula(full_formula3, data=df_lagged)
result3 = model3.fit()
print(result3.summary)

# rmsle
rmsle3 = compute_rmsle_from_result(result3, df_final)

# ëª¨ë¸3 ê²°ê³¼ ì €ì¥ 
save_full_model_output(result3,rmsle3,"./model/model3_results.csv")

# ìµœì¢…ë°ì´í„°ì…‹ export
df_reg_final = df_final.reset_index()
df_reg_final.to_csv('./model/df_reg_final.csv',encoding='utf-8-sig', index=False)


# ===========================================================
# 2. ìœ ì˜í•œ ë³€ìˆ˜ë¥¼ í†µí•´ clustering
#  - ê³µí†µì „ì²˜ë¦¬(ìŠ¤ì¼€ì¼ë§, SPCA)
#  [Part1. ê³„ì¸µì  Clustering]
#  [Part2. K-means í´ëŸ¬ìŠ¤í„°ë§]
#  [Part3. ë³‘í•© ë° í´ëŸ¬ìŠ¤í„°ë§ ëª…ì¹­ë¶€ì—¬]
# ===========================================================
df_for_cluster = pd.read_csv('./model/ìƒê¶Œ_ì°©í•œê°€ê²©ì—…ì†Œ_ë³‘í•©.csv', encoding='utf-8')

# ë”ë¯¸ë³€ìˆ˜ ìƒì„±
df_for_cluster = pd.get_dummies(df_for_cluster, columns=['ìƒê¶Œ_ë³€í™”_ì§€í‘œ'], drop_first=False)

# ì™œë„ í™•ì¸ & ë¡œê·¸ë³€í™˜ 
skew_test_columns = [
    'ì—…ì†Œìˆ˜',
    'ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘',
    'ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡',
    'ì›”_í‰ê· _ì†Œë“_ê¸ˆì•¡',
    'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡',
    'ì˜ë£Œë¹„_ì§€ì¶œ_ì´ê¸ˆì•¡',
    'êµìœ¡_ì§€ì¶œ_ì´ê¸ˆì•¡',
    'ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜',
    'ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€',
    'ìœ ë™ì¸êµ¬_10_30ëŒ€',
    'ìœ ë™ì¸êµ¬_40_ì´ìƒ',
    'ì´_ì§ì¥ì¸êµ¬_ìˆ˜',
    'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜',
    'ì§‘ê°ì‹œì„¤_ìˆ˜',
    'ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´',
    'íì—…_ì˜ì—…_ê°œì›”_ì°¨ì´',
    'ê°œì—…_ë¥ ',
    'íì—…_ë¥ ',
    '1ì¸_ê°€êµ¬ë¹„',
    '20_30_ì¸êµ¬ë¹„',
    '31_50_ì¸êµ¬ë¹„',
    '51_75_ì¸êµ¬ë¹„'
]

check_variable_skewness(df_for_cluster[skew_test_columns])

skew_columns = skew_test_columns.copy()
skew_columns.remove('ì´_ìƒì£¼ì¸êµ¬_ìˆ˜')       # ìƒì£¼ì¸êµ¬ìˆ˜ ëŒ€ì¹­ 
skew_columns.remove('íì—…_ì˜ì—…_ê°œì›”_ì°¨ì´')
skew_columns.remove('ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´')

# ìµœì¢…í™•ì •ëœ ë³€ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¡œê·¸ë³€í™˜ 
df_for_cluster = apply_log_transform(df_for_cluster, skew_columns)

# 9. ë…ë¦½ë³€ìˆ˜ ìµœì¢…í™•ì • 
# - ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log, ì§‘ê°ì‹œì„¤ ìˆ˜, ìš´ì˜_ì˜ì—…_ê°œì›”_ì°¨ì´ëŠ” ë‹¤ì¤‘ê³µì„ ì„±ì´ ë†’ì•„ ì œê±°
scale_columns = [
    'ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡_log',
    'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'ì˜ë£Œë¹„_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'êµìœ¡_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log',
    'ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜_log',
    'ìœ ë™ì¸êµ¬_10_30ëŒ€_log',
    'ìœ ë™ì¸êµ¬_40_ì´ìƒ_log',
    'ì´_ì§ì¥ì¸êµ¬_ìˆ˜_log',
    'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜',
    'ì§‘ê°ì‹œì„¤_ìˆ˜_log',
    'ê°œì—…_ë¥ _log',
    'íì—…_ë¥ _log',
    '1ì¸_ê°€êµ¬ë¹„_log',
    '20_30_ì¸êµ¬ë¹„_log',
    '31_50_ì¸êµ¬ë¹„_log'
]

# ë…ë¦½ë³€ìˆ˜ ë‹¨ìœ„ ìŠ¤ì¼€ì¼ë§
df_for_cluster = apply_zscore_scaling(df_for_cluster, scale_columns)

# â–¶ ìœ ì˜ë³€ìˆ˜ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ìš© ë°ì´í„° ì¶”ì¶œ
features = [
    'ì í¬ìˆ˜_ëŒ€ë¹„_ë§¤ì¶œì•¡_log',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LH',
    'ìƒê¶Œ_ë³€í™”_ì§€í‘œ_LL',
    'íì—…_ë¥ _log',
    'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡_log',
    'ì•„íŒŒíŠ¸_í‰ê· _ì‹œê°€_log',
    'ì•„íŒŒíŠ¸_ë‹¨ì§€_ìˆ˜_log',
    'ìœ ë™ì¸êµ¬_10_30ëŒ€_log',
    'ìœ ë™ì¸êµ¬_40_ì´ìƒ_log',
    'ì´_ì§ì¥ì¸êµ¬_ìˆ˜_log',
    'ì§‘ê°ì‹œì„¤_ìˆ˜_log',
    'ì´_ìƒì£¼ì¸êµ¬_ìˆ˜',
    '20_30_ì¸êµ¬ë¹„_log',
    '31_50_ì¸êµ¬ë¹„_log'
]
y_var = 'ì°©í•œê°€ê²©_ì—…ì†Œìˆ˜_ë¹„ì¤‘'
df_spca = df_for_cluster[[y_var]+features].dropna().copy()

# â–¶ ìŠ¤ì¼€ì¼ë§ (ì—°ì†í˜•ë§Œ)
#scale_vars = ['íì—…_ë¥ ', 'ìŒì‹_ì§€ì¶œ_ì´ê¸ˆì•¡', '20_30_ì¸êµ¬ë¹„']
#dummy_vars = ['ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL']
#scaler = StandardScaler()
#X_scaled = scaler.fit_transform(df_spca[scale_vars])
#X_dummy = df_spca[['ìƒê¶Œ_ë³€í™”_ì§€í‘œ_HL']].astype(float).values

X_final = df_spca[features]
y = df_spca[y_var]

# â–¶ PCA 2ì°¨ì› ì¶•ì†Œ
pls = PLSRegression(n_components=2)
X_pls = pls.fit_transform(X_final, y)[0]  # ì£¼ì„±ë¶„ ì ìˆ˜ë§Œ ì¶”ì¶œ

# â–¶ ê³µí†µ ê²°ê³¼ ì €ì¥ìš© DF
df_pls_clustered = pd.DataFrame(X_pls, columns=['SPC1', 'SPC2'], index=df_spca.index)

# PLS(SPC í•´ì„) 
# ì´ë ‡ê²Œ ì„¸ ê°€ì§€ë¥¼ í•¨ê»˜ ë³´ê³  í•´ì„í•˜ë©´:
# ì–´ë–¤ ë³€ìˆ˜ë“¤ì´ ì¶• êµ¬ì„±ì— ì¤‘ìš”í–ˆê³  (weights)
# ì‹¤ì œ ë°ì´í„° ë¶„ì‚°ì„ ì–¼ë§ˆë‚˜ ì„¤ëª…í–ˆê³  (loadings)
# ê²°ê³¼ì ìœ¼ë¡œ Yì— ì–´ë–¤ ì˜í–¥ì„ ì£¼ëŠ”ì§€(coef) ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
df_pls_weights = pd.DataFrame(pls.x_weights_, columns=['SPC1', 'SPC2'], index=features)
df_pls_loadings = pd.DataFrame(pls.x_loadings_, columns=['SPC1', 'SPC2'], index=features)
df_pls_coef = pd.DataFrame(pls.coef_.T, index=features, columns=['PLS_Coefficient'])

df_pls_weights.index.name = "feature"  # ì¸ë±ìŠ¤ ì´ë¦„ ì„¤ì •
df_pls_loadings.index.name = "feature"  # ì¸ë±ìŠ¤ ì´ë¦„ ì„¤ì •
df_pls_coef.index.name = "feature"  # ì¸ë±ìŠ¤ ì´ë¦„ ì„¤ì •

# pls í•´ì„ì„ ìœ„í•œ ë¦¬í”„í† 
df_pls_weights.to_csv("./model/pls_weights.csv", index=True, encoding="utf-8-sig")
df_pls_loadings.to_csv("./model/pls_loadings.csv", index=True, encoding="utf-8-sig")
df_pls_coef.to_csv("./model/pls_coef.csv", index=True, encoding="utf-8-sig")

# ---------------------------------------
# [Part1. ê³„ì¸µì  Clustering]
# ---------------------------------------
Z = linkage(X_pls, method='ward')
hier_labels = fcluster(Z, t=4, criterion='maxclust')

df_pls_clustered['hier_cluster'] = hier_labels

# ---------------------------------------
# [Part2. K-means í´ëŸ¬ìŠ¤í„°ë§]
# ---------------------------------------
kmeans = KMeans(n_clusters=4, random_state=42, n_init='auto')
kmeans_labels = kmeans.fit_predict(X_pls)

df_pls_clustered['kmeans_cluster'] = kmeans_labels

# ---------------------------------------
# [Part3. ë³‘í•© ë° í´ëŸ¬ìŠ¤í„°ë§ ëª…ì¹­ë¶€ì—¬]
# ---------------------------------------
# ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© (ë‘˜ ë‹¤ ë™ì¼í•œ ìˆœì„œì¼ ê²½ìš°)
df_cluster = df_for_cluster.join(df_pls_clustered)

# SPC1, SPC2 ì¶• ì´ë¦„ ì¬ì •ì˜ (ì˜ˆ: ì†Œë¹„ì¶•, ì Šì€ì¸µì¶• ë“±)
df_cluster = df_cluster.rename(columns={
    'SPC1': 'ì†Œë¹„í™œì„±ë„ ì¶•',
    'SPC2': 'ì²­ë…„ë°€ì§‘ë„ ì¶•'
})

# í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ì— ë”°ë¥¸ ëª…ì¹­ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
hier_cluster_labels = {
    1: 'ì²­ë…„ ë°€ì§‘Â·ê³ ì†Œë¹„ ì§€ì—­',
    2: 'ì²­ë…„ ë°€ì§‘Â·ì €ì†Œë¹„ ì§€ì—­',
    3: 'ì¤‘ì¥ë…„ ë°€ì§‘Â·ì €ì†Œë¹„ ì§€ì—­',
    4: 'ìµœëŒ€ì†Œë¹„ ì§€ì—­',
}

# í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ì— ë”°ë¥¸ ëª…ì¹­ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
kmeans_cluster_labels = {
    0: 'ìµœëŒ€ì†Œë¹„ ì§€ì—­',
    1: 'ì²­ë…„ ë°€ì§‘Â·ì €ì†Œë¹„ ì§€ì—­',
    2: 'ì¤‘ì¥ë…„ ë°€ì§‘Â·ì €ì†Œë¹„ ì§€ì—­',
    3: 'ì²­ë…„ ë°€ì§‘Â·ê³ ì†Œë¹„ ì§€ì—­'
}

# ìƒˆë¡œìš´ ì»¬ëŸ¼ ìƒì„± (ê¸°ì¡´ ìˆ«ì í´ëŸ¬ìŠ¤í„° ìœ ì§€ë„ ê°€ëŠ¥)
df_cluster['hier_cluster_label'] = df_cluster['hier_cluster'].map(hier_cluster_labels)
df_cluster['kmeans_cluster_label'] = df_cluster['kmeans_cluster'].map(kmeans_cluster_labels)

# ìµœì¢… í´ëŸ¬ìŠ¤í„°ë§ ë°ì´í„°ì…‹  
df_cluster.to_csv('./model/final_cluster.csv',encoding='utf-8-sig', index=False)


# ===========================================================
#  etc. í´ëŸ¬ìŠ¤í„°ë§ ëœ ì§€ë„ì‹œê°í™” êµ°ì§‘ë³„ë¡œ html export
# ===========================================================
# ì§€ì—­ë³„ í´ëŸ¬ìŠ¤í„°*ì°©í•œê°€ê²©ì—…ì†Œìˆ˜ ë¹„ì¤‘ ì§€ë„ì‹œê°í™”
gdf = load_clustered_geodataframe()
save_all_clusters_goodprice_map(gdf)




# ===========================================================
# 3. ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬ ì „ëµë¶„ì„
# ===========================================================
df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹ = pd.read_csv('./model/ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹í™”.csv')

#ì¹´ì´ì œê³±ê²€ì • ë³€ìˆ˜ë¦¬ìŠ¤íŠ¸
category_cols = [
    'ì •ë¶€ì§€ì›ì •ì±…_ì¶”ì§„ì •ì±…1ì½”ë“œëª…',
    'ì •ë¶€ì§€ì›ì •ì±…_ì¶”ì§„ì •ì±…2ì½”ë“œëª…',
    'ì‚¬ì—…ì „í™˜_ìš´ì˜ê³„íšì½”ë“œëª…',
    'ê²½ì˜_ìš´ì˜í™œë™ì½”ë“œ1ëª…'
]

# ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
t_results = []

for col in category_cols:
    # êµì°¨í‘œ ìƒì„±
    ct = pd.crosstab(df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹['ê·¸ë£¹êµ¬ë¶„'], df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹[col])

    # ê²°ì¸¡ì¹˜ë¡œ ì¸í•œ ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì—´ ê°œìˆ˜ê°€ 2ê°œ ì´ìƒì¸ì§€ í™•ì¸
    if ct.shape[1] < 2:
        t_results.append({
            'ë³€ìˆ˜': col,
            'ì¹´ì´ì œê³± í†µê³„ëŸ‰': None,
            'pê°’': None,
            'ê²°ë¡ ': 'ìœ íš¨í•œ ë¹„êµ ë¶ˆê°€ (ì¹´í…Œê³ ë¦¬ ë¶€ì¡±)'
        })
        continue

    # ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •
    chi2, p, dof, expected = chi2_contingency(ct)

    # ê²°ê³¼ ì €ì¥
    t_results.append({
        'ë³€ìˆ˜': col,
        'ì¹´ì´ì œê³± í†µê³„ëŸ‰': round(chi2, 3),
        'pê°’': round(p, 4),
        'ê²°ë¡ ': 'ìœ ì˜ë¯¸í•œ ì°¨ì´ ìˆìŒ' if p < 0.05 else 'ì°¨ì´ ì—†ìŒ'
    })

# ê²°ê³¼ ì¶œë ¥
t_results_df = pd.DataFrame(t_results)
print(t_results_df)



z_results = []

for col in category_cols:
    ct = pd.crosstab(df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹['ê·¸ë£¹êµ¬ë¶„'], df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹[col])

    # ì¹´í…Œê³ ë¦¬ê°€ 2ê°œ ì´ìƒì´ì–´ì•¼ ë¹„êµ ì˜ë¯¸ ìˆìŒ
    if ct.shape[1] < 2:
        z_results.append({
            'ë³€ìˆ˜': col,
            'ë¹„êµë°©ì‹': 'ë¹„ìœ¨ z-test',
            'ê²°ë¡ ': 'ìœ íš¨í•œ ë¹„êµ ë¶ˆê°€ (ì¹´í…Œê³ ë¦¬ ë¶€ì¡±)'
        })
        continue

    for cat in ct.columns:
        count = ct[cat].values
        nobs = ct.sum(axis=1).values

        if len(count) == 2 and all(nobs > 0):
            stat, pval = proportions_ztest(count, nobs)
            z_results.append({
                'ë³€ìˆ˜': col,
                'ì¹´í…Œê³ ë¦¬': cat,
                'zê°’': round(stat, 3),
                'pê°’': round(pval, 4),
                'ê²°ë¡ ': 'ìœ ì˜ë¯¸í•œ ë¹„ìœ¨ ì°¨ì´ ìˆìŒ' if pval < 0.05 else 'ì°¨ì´ ì—†ìŒ'
            })
        else:
            z_results.append({
                'ë³€ìˆ˜': col,
                'ì¹´í…Œê³ ë¦¬': cat,
                'ê²°ë¡ ': 'ë¹„êµ ë¶ˆê°€ (ìƒ˜í”Œ ë¶€ì¡±)'
            })

z_results_df = pd.DataFrame(z_results)
print(z_results_df)


z_results_df[z_results_df['ê²°ë¡ '] == 'ìœ ì˜ë¯¸í•œ ë¹„ìœ¨ ì°¨ì´ ìˆìŒ']


plot_grouped_bar_ratio(df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹,'ì •ë¶€ì§€ì›ì •ì±…_ì¶”ì§„ì •ì±…1ì½”ë“œëª…')
plot_grouped_bar_ratio(df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹,'ì •ë¶€ì§€ì›ì •ì±…_ì¶”ì§„ì •ì±…2ì½”ë“œëª…')
plot_grouped_bar_ratio(df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹,'ì‚¬ì—…ì „í™˜_ìš´ì˜ê³„íšì½”ë“œëª…')
plot_grouped_bar_ratio(df_ì†Œìƒê³µì¸ì‹¤íƒœì¡°ì‚¬_ê·¸ë£¹,'ê²½ì˜_ìš´ì˜í™œë™ì½”ë“œ1ëª…')

